{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf660484",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukev\\Documents\\SOPlijner\\SOPlijner\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets...\n",
      "Loading finetuning model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1887\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='236' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 33/236 00:03 < 00:23, 8.77 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     nl_nli_results \u001b[38;5;241m=\u001b[39m evaluate_nl_nli_models()\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#stress_test_results_insick = evaluate_switched_sicks()\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m#stress_test_results = evaluate_stress_tests()\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#sick_en_relatedness_results = evaluate_en_models()\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#sick_nl_relatedness_results = evaluate_nl_models()\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     en_nli_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_en_nli_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     nl_nli_results \u001b[38;5;241m=\u001b[39m evaluate_nl_nli_models()\n",
      "File \u001b[1;32m~\\Documents\\SOPlijner\\SOPlijner\\sick_nl\\code\\evaluation\\eval_nli.py:61\u001b[0m, in \u001b[0;36mevaluate_en_nli_models\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m en_sick_plus_mednli \u001b[38;5;241m=\u001b[39m load_sick_plus_mednli_en()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# run_finetuner(en_sick, bert, setting='bert', num_epochs=20, model_folder=models_folder, result_folder=results_folder)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# run_finetuner(en_sick, roberta, setting='roberta', num_epochs=20, model_folder=models_folder, result_folder=results_folder)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# run_finetuner(en_sick, mbert, setting='bert', num_epochs=20, model_folder=models_folder, result_folder=results_folder)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# run_finetuner(en_mednli, bert, setting='bert', num_epochs=20, model_folder=models_folder, result_folder=results_folder)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# run_finetuner(en_mednli, roberta, setting='roberta', num_epochs=20, model_folder=models_folder, result_folder=results_folder)\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# run_finetuner(en_mednli, mbert, setting='bert', num_epochs=20, model_folder=models_folder, result_folder=results_folder)\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m \u001b[43mrun_finetuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43men_sick_plus_mednli\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodels_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m run_finetuner(en_sick_plus_mednli, roberta, setting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m'\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, model_folder\u001b[38;5;241m=\u001b[39mmodels_folder, result_folder\u001b[38;5;241m=\u001b[39mresults_folder)\n\u001b[0;32m     63\u001b[0m run_finetuner(en_sick_plus_mednli, mbert, setting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m'\u001b[39m, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, model_folder\u001b[38;5;241m=\u001b[39mmodels_folder, result_folder\u001b[38;5;241m=\u001b[39mresults_folder)\n",
      "File \u001b[1;32m~\\Documents\\SOPlijner\\SOPlijner\\sick_nl\\code\\evaluation\\eval_nli.py:38\u001b[0m, in \u001b[0;36mrun_finetuner\u001b[1;34m(sick_dataset, name, setting, num_epochs, model_folder, result_folder, evaluating)\u001b[0m\n\u001b[0;32m     36\u001b[0m tuner \u001b[38;5;241m=\u001b[39m load_bert_nli_model(sick_dataset, name, setting, num_epochs, evaluating)\n\u001b[0;32m     37\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 38\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m save_results(result_folder, eval_results, sick_dataset\u001b[38;5;241m.\u001b[39mname, name)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epochs......\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\SOPlijner\\SOPlijner\\sick_nl\\code\\models\\bert_finetune.py:150\u001b[0m, in \u001b[0;36mBERTFineTuner.evaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\both\\lib\\site-packages\\transformers\\trainer.py:2621\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2618\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   2620\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 2621\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   2626\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2631\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   2632\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m   2633\u001b[0m     speed_metrics(\n\u001b[0;32m   2634\u001b[0m         metric_key_prefix,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2638\u001b[0m     )\n\u001b[0;32m   2639\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\both\\lib\\site-packages\\transformers\\trainer.py:2821\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2815\u001b[0m     inputs_host \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2816\u001b[0m         inputs_decode\n\u001b[0;32m   2817\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inputs_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2818\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m nested_concat(inputs_host, inputs_decode, padding_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m   2819\u001b[0m     )\n\u001b[0;32m   2820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2821\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2822\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_gather(logits)\n\u001b[0;32m   2823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\both\\lib\\site-packages\\transformers\\trainer.py:2955\u001b[0m, in \u001b[0;36mTrainer._pad_across_processes\u001b[1;34m(self, tensor, pad_index)\u001b[0m\n\u001b[0;32m   2953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n\u001b[0;32m   2954\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[1;32m-> 2955\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m   2956\u001b[0m sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nested_gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m   2958\u001b[0m max_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(s[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m sizes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "    \n",
    "from evaluation.eval_nli \\\n",
    "    import evaluate_en_nli_models, evaluate_nl_nli_models\n",
    "\n",
    "def main():\n",
    "    #sick_en_relatedness_results = evaluate_en_models()\n",
    "    #sick_nl_relatedness_results = evaluate_nl_models()\n",
    "    en_nli_results = evaluate_en_nli_models()\n",
    "    nl_nli_results = evaluate_nl_nli_models()\n",
    "    #stress_test_results_insick = evaluate_switched_sicks()\n",
    "    #stress_test_results = evaluate_stress_tests()\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91650ce2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7187b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b478a072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8dc476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc47135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf661e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fb4658c42b2156261d0674025e2c0b96135277fd716db413e043e5966c6fd55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
